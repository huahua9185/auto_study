#!/usr/bin/env python3
"""
URLæŸ¥æ‰¾è„šæœ¬

è‡ªåŠ¨æ¢æµ‹ç›®æ ‡ç½‘ç«™çš„ç™»å½•é¡µé¢å’Œè¯¾ç¨‹é¡µé¢URL
"""

import asyncio
import re
import sys
from pathlib import Path
from urllib.parse import urljoin, urlparse
from typing import List, Dict, Optional, Set

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from playwright.async_api import async_playwright
from src.auto_study.utils.logger import logger


class URLFinder:
    """URLæŸ¥æ‰¾å™¨"""
    
    def __init__(self, base_url: str = "https://edu.nxgbjy.org.cn"):
        self.base_url = base_url
        self.browser = None
        self.context = None
        self.page = None
        
        # å¸¸è§çš„ç™»å½•é¡µé¢æ ‡è¯†
        self.login_indicators = [
            'login', 'ç™»å½•', 'ç™»é™†', 'signin', 'sign-in', 
            'user/login', 'auth/login', 'account/login',
            'member/login', 'student/login', 'index.html'
        ]
        
        # å¸¸è§çš„è¯¾ç¨‹é¡µé¢æ ‡è¯†
        self.course_indicators = [
            'course', 'courses', 'è¯¾ç¨‹', 'study', 'learning',
            'class', 'classes', 'lesson', 'lessons',
            'education', 'training', 'module', 'modules'
        ]
        
        # å·²è®¿é—®çš„URLï¼Œé¿å…é‡å¤
        self.visited_urls: Set[str] = set()
        
    async def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨"""
        try:
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(
                headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨ä»¥ä¾¿è§‚å¯Ÿ
                slow_mo=100,     # æ…¢åŠ¨ä½œä¾¿äºè§‚å¯Ÿ
                args=[
                    '--no-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-web-security'
                ]
            )
            
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            self.page = await self.context.new_page()
            logger.info("æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            raise
    
    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        try:
            if self.page:
                await self.page.close()
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if hasattr(self, 'playwright'):
                await self.playwright.stop()
            logger.info("æµè§ˆå™¨å…³é—­å®Œæˆ")
        except Exception as e:
            logger.error(f"å…³é—­æµè§ˆå™¨å¤±è´¥: {e}")
    
    async def get_page_links(self, url: str) -> List[Dict[str, str]]:
        """è·å–é¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        try:
            logger.info(f"è®¿é—®é¡µé¢: {url}")
            await self.page.goto(url, wait_until='networkidle')
            await asyncio.sleep(2)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            
            # è·å–æ‰€æœ‰é“¾æ¥
            links = await self.page.evaluate("""
                () => {
                    const links = [];
                    const elements = document.querySelectorAll('a[href], button[onclick], div[onclick]');
                    
                    elements.forEach(el => {
                        let href = el.href || '';
                        let text = el.textContent?.trim() || '';
                        let onclick = el.getAttribute('onclick') || '';
                        
                        // å¤„ç†onclickä¸­çš„é“¾æ¥
                        if (onclick) {
                            const urlMatch = onclick.match(/['"]([^'"]*\.html?)['"]/) || 
                                           onclick.match(/location\.href\s*=\s*['"]([^'"]*)['"]/);
                            if (urlMatch) {
                                href = urlMatch[1];
                            }
                        }
                        
                        if (href && text) {
                            links.push({
                                href: href,
                                text: text,
                                tag: el.tagName.toLowerCase(),
                                onclick: onclick
                            });
                        }
                    });
                    
                    return links;
                }
            """)
            
            logger.info(f"æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
            return links
            
        except Exception as e:
            logger.error(f"è·å–é¡µé¢é“¾æ¥å¤±è´¥ {url}: {e}")
            return []
    
    def normalize_url(self, url: str, base_url: str) -> str:
        """è§„èŒƒåŒ–URL"""
        if not url:
            return ""
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if url.startswith('//'):
            return f"https:{url}"
        elif url.startswith('/'):
            return urljoin(base_url, url)
        elif not url.startswith(('http://', 'https://')):
            return urljoin(base_url, url)
        
        return url
    
    def is_login_url(self, url: str, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç™»å½•URL"""
        url_lower = url.lower()
        text_lower = text.lower()
        
        return any(indicator in url_lower or indicator in text_lower 
                  for indicator in self.login_indicators)
    
    def is_course_url(self, url: str, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯è¯¾ç¨‹URL"""
        url_lower = url.lower()
        text_lower = text.lower()
        
        return any(indicator in url_lower or indicator in text_lower 
                  for indicator in self.course_indicators)
    
    async def find_urls(self) -> Dict[str, List[Dict[str, str]]]:
        """æŸ¥æ‰¾ç™»å½•å’Œè¯¾ç¨‹URL"""
        results = {
            'login_urls': [],
            'course_urls': [],
            'all_urls': []
        }
        
        try:
            # é¦–å…ˆè®¿é—®ä¸»é¡µ
            logger.info(f"å¼€å§‹åˆ†æç½‘ç«™: {self.base_url}")
            main_links = await self.get_page_links(self.base_url)
            
            # åˆ†æä¸»é¡µé“¾æ¥
            for link in main_links:
                href = self.normalize_url(link['href'], self.base_url)
                if not href or href in self.visited_urls:
                    continue
                
                self.visited_urls.add(href)
                text = link['text']
                
                url_info = {
                    'url': href,
                    'text': text,
                    'found_on': self.base_url,
                    'tag': link.get('tag', 'a'),
                    'onclick': link.get('onclick', '')
                }
                
                results['all_urls'].append(url_info)
                
                # åˆ¤æ–­URLç±»å‹
                if self.is_login_url(href, text):
                    results['login_urls'].append(url_info)
                    logger.info(f"ğŸ” å‘ç°ç™»å½•é“¾æ¥: {text} -> {href}")
                
                if self.is_course_url(href, text):
                    results['course_urls'].append(url_info)
                    logger.info(f"ğŸ“š å‘ç°è¯¾ç¨‹é“¾æ¥: {text} -> {href}")
            
            # å°è¯•è®¿é—®ä¸€äº›å¸¸è§çš„ç™»å½•é¡µé¢è·¯å¾„
            common_login_paths = [
                '/login', '/login.html', '/user/login', '/auth/login',
                '/nxxzxy/index.html', '/student/login', '/member/login'
            ]
            
            for path in common_login_paths:
                test_url = urljoin(self.base_url, path)
                if test_url not in self.visited_urls:
                    try:
                        await self.page.goto(test_url, timeout=10000)
                        if self.page.url != test_url:
                            # å‘ç”Ÿäº†é‡å®šå‘
                            logger.info(f"ğŸ”„ {test_url} é‡å®šå‘åˆ°: {self.page.url}")
                            url_info = {
                                'url': self.page.url,
                                'text': f'é‡å®šå‘è‡ª {path}',
                                'found_on': test_url,
                                'tag': 'redirect'
                            }
                            results['login_urls'].append(url_info)
                        else:
                            # é¡µé¢å­˜åœ¨
                            logger.info(f"âœ… æ‰¾åˆ°ç™»å½•é¡µé¢: {test_url}")
                            url_info = {
                                'url': test_url,
                                'text': f'ç›´æ¥è®¿é—® {path}',
                                'found_on': self.base_url,
                                'tag': 'direct'
                            }
                            results['login_urls'].append(url_info)
                        
                        self.visited_urls.add(test_url)
                        
                    except Exception as e:
                        logger.debug(f"æ— æ³•è®¿é—® {test_url}: {e}")
            
            return results
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾URLå¤±è´¥: {e}")
            return results
    
    def print_results(self, results: Dict[str, List[Dict[str, str]]]):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ” URL æŸ¥æ‰¾ç»“æœ")
        print("="*80)
        
        print(f"\nğŸ” ç™»å½•é¡µé¢å€™é€‰ ({len(results['login_urls'])} ä¸ª):")
        print("-" * 50)
        for i, url_info in enumerate(results['login_urls'], 1):
            print(f"{i}. {url_info['text']}")
            print(f"   URL: {url_info['url']}")
            print(f"   å‘ç°äº: {url_info['found_on']}")
            if url_info.get('onclick'):
                print(f"   ç‚¹å‡»äº‹ä»¶: {url_info['onclick'][:100]}...")
            print()
        
        print(f"\nğŸ“š è¯¾ç¨‹é¡µé¢å€™é€‰ ({len(results['course_urls'])} ä¸ª):")
        print("-" * 50)
        for i, url_info in enumerate(results['course_urls'], 1):
            print(f"{i}. {url_info['text']}")
            print(f"   URL: {url_info['url']}")
            print(f"   å‘ç°äº: {url_info['found_on']}")
            if url_info.get('onclick'):
                print(f"   ç‚¹å‡»äº‹ä»¶: {url_info['onclick'][:100]}...")
            print()
        
        print(f"\nğŸ“‹ æ‰€æœ‰å‘ç°çš„é“¾æ¥ ({len(results['all_urls'])} ä¸ª):")
        print("-" * 50)
        for i, url_info in enumerate(results['all_urls'], 1):
            print(f"{i:2d}. {url_info['text'][:30]:<30} -> {url_info['url']}")
        
        # ç”Ÿæˆé…ç½®å»ºè®®
        print(f"\nâš™ï¸  é…ç½®æ–‡ä»¶å»ºè®®:")
        print("-" * 50)
        
        if results['login_urls']:
            best_login = results['login_urls'][0]['url']
            print(f"login_url: \"{best_login}\"")
        
        if results['course_urls']:
            best_course = results['course_urls'][0]['url']
            print(f"courses_url: \"{best_course}\"")
        
        if not results['login_urls']:
            print("âš ï¸  æœªæ‰¾åˆ°æ˜æ˜¾çš„ç™»å½•é¡µé¢ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥")
        
        if not results['course_urls']:
            print("âš ï¸  æœªæ‰¾åˆ°æ˜æ˜¾çš„è¯¾ç¨‹é¡µé¢ï¼Œå¯èƒ½éœ€è¦ç™»å½•åæ‰èƒ½è®¿é—®")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æŸ¥æ‰¾ç½‘ç«™çš„ç™»å½•å’Œè¯¾ç¨‹URL")
    parser.add_argument("--url", type=str, default="https://edu.nxgbjy.org.cn", 
                       help="ç›®æ ‡ç½‘ç«™URL (é»˜è®¤: https://edu.nxgbjy.org.cn)")
    parser.add_argument("--headless", action="store_true", 
                       help="æ— å¤´æ¨¡å¼è¿è¡Œ")
    
    args = parser.parse_args()
    
    finder = URLFinder(args.url)
    
    try:
        await finder.start_browser()
        results = await finder.find_urls()
        finder.print_results(results)
        
        # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹ç»“æœ
        if not args.headless:
            input("\næŒ‰å›è½¦é”®å…³é—­æµè§ˆå™¨...")
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await finder.close_browser()


if __name__ == "__main__":
    asyncio.run(main())